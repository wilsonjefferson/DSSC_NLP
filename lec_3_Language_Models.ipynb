{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "lec_3_Language Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8BGYonOGP0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c38b4e-b60a-41fb-8c80-df2dafb54263"
      },
      "source": [
        "! pip install wget\n",
        "import wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=e7f68b6a3ae56becdb04c1eb65e5be8196b33f10cc62d9964c2bde393950a599\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJjCXG1IGPdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6373af6d-b2ef-4e0a-dd25-e313ecc34ce4"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/dirkhovy/NLPclass/master/data/moby_dick.txt'\n",
        "wget.download(url, 'moby_dick.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'moby_dick.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8EH2_u-Fugs"
      },
      "source": [
        "# Language Models\n",
        "\n",
        "Let's start with a simple, Laplace-smoothed trigram model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U00eZfVGFugw"
      },
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "smoothing = 0.001\n",
        "START = '_***_'\n",
        "STOP = '_STOP_'\n",
        "\n",
        "# map from (u, v) to w = (w|u,v)\n",
        "counts = defaultdict(lambda: defaultdict(lambda: smoothing))\n",
        "\n",
        "# fit data on corpus\n",
        "corpus = [line.strip().split() for line in open('moby_dick.txt')]\n",
        "\n",
        "# collect counts for MLE\n",
        "for sentence in corpus:\n",
        "    # include special tokens for start and the end of sentence\n",
        "    tokens = [START, START] + sentence + [STOP]\n",
        "    for u, v, w in nltk.ngrams(tokens, 3):\n",
        "        counts[(u, v)][w] += 1\n",
        "\n",
        "def logP(u, v, w):\n",
        "    \"\"\"\n",
        "    compute the log probability of a trigram\n",
        "    (u,v,w) => P(w|u,v) = c(u,v,w) / SUM(c(u,v,*))\n",
        "    \"\"\"\n",
        "    return np.log(counts[(u, v)][w]) - np.log(sum(counts[(u, v)].values()))\n",
        "\n",
        "def sentence_logP(S):\n",
        "    \"\"\"\n",
        "    score a sentence in log likelihood with chain rule\n",
        "    S: list(str)\n",
        "    \"\"\"\n",
        "    tokens = [START, START] + S + [STOP]\n",
        "    return sum([logP(u, v, w) for u, v, w in nltk.ngrams(tokens, 3)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug3awRv5tUy8",
        "outputId": "57d73c20-fa34-45b9-9f34-fe5db96a50d0"
      },
      "source": [
        "sum(counts[('because','they')].values())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoFO0lO1FuhA"
      },
      "source": [
        "We can now score arbitrary sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwJBkbQrFuhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f43926-35b5-4fb4-c0ba-bcf949622cca"
      },
      "source": [
        "sentence_logP('Captain Ahab is a man .'.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-27.92672048112014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyWmWgyou_s3",
        "outputId": "58baa68b-1a97-4ec3-f9eb-422cf4b4e80d"
      },
      "source": [
        "sentence_logP('Captain Ahab is a woman .'.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-32.49967973437645"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybbofi_lkgFy"
      },
      "source": [
        "counts[('you','are')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqSc6ksAipHf"
      },
      "source": [
        "sum(counts[('you','are')].values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz04HP-vFuh8"
      },
      "source": [
        "## Activity\n",
        "Implement the perplexity measure for a given corpus, and try it with two LM with different smoothing parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIPDCI6eFuh_"
      },
      "source": [
        "$$perplexity = 2^{-\\sum_{x \\in X} p(x) \\log p(x)}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTSRyIN4FuiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9933bd-f739-493b-f537-c367c2be32e9"
      },
      "source": [
        "def get_perplexity(corpus):\n",
        "    \"\"\"\n",
        "    perplexity = 2^-entropy(X)\n",
        "    entropy = -sum(p(x) *log(p(x)))\n",
        "    \"\"\"\n",
        "    entropy = 0.0\n",
        "    for sentence in corpus:\n",
        "        sentence_log_prob = sentence_logP(sentence)\n",
        "        sentence_entropy = np.exp(sentence_log_prob) * sentence_log_prob\n",
        "        entropy += sentence_entropy\n",
        "        \n",
        "    perplexity = 2 ** -entropy\n",
        "    return perplexity\n",
        "\n",
        "print(get_perplexity(corpus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.118431256864183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGfhZxlhFuiL"
      },
      "source": [
        "## Generation\n",
        "\n",
        "We can re-use the counts to generate language:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL9kdmiEFuiN"
      },
      "source": [
        "def generate():\n",
        "    result = [START, START]\n",
        "    next_word = sample_next_word(result[-2], result[-1])\n",
        "    result.append(next_word)\n",
        "    while next_word != STOP:\n",
        "        next_word = sample_next_word(result[-2], result[-1])\n",
        "        result.append(next_word)\n",
        "    \n",
        "    return ' '.join(result[2:-1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def sample_next_word(u, v):\n",
        "    \"\"\"\n",
        "    sample a word w based on the history (u, v)\n",
        "    \"\"\"\n",
        "    # separate word and their counts into separate variables\n",
        "    keys, values = zip(*counts[(u, v)].items())\n",
        "    \n",
        "    # normalize the counts into a probability distribution\n",
        "    values = np.array(values)\n",
        "    values /= values.sum() # create probability distro\n",
        "    \n",
        "    # this is the meat of the function\n",
        "    sample = np.random.multinomial(1, values) # pick one position\n",
        "    \n",
        "    return keys[np.argmax(sample)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy6lHvJRyatM",
        "outputId": "8b4c6f60-df37-40c5-ac19-333643314f63"
      },
      "source": [
        "keys, values = zip(*counts[('you','are')].items())\n",
        "values = np.array(values)\n",
        "values /= values.sum()\n",
        "values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10339363, 0.03448751, 0.03448751, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.03448751, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.10339363, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.03448751, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.03448751, 0.03448751, 0.03448751])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh-Xqf-zzQwd",
        "outputId": "945d4d91-8567-4dd0-e522-b6c70833d052"
      },
      "source": [
        "sample = np.random.multinomial(1, values)\n",
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-IHjf2Jtz1w2",
        "outputId": "cbab6042-fc39-4410-ab1c-4cae11686cd5"
      },
      "source": [
        "keys[np.argmax(sample)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'skylarking'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "MsqbTApXFuiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd807ac-c507-4448-c646-000fe9d61a1b"
      },
      "source": [
        "for i in range(50):\n",
        "    keys, values = zip(*counts[('you','are')].items())\n",
        "    values = np.array(values)\n",
        "    values /= values.sum()\n",
        "    sample = np.random.multinomial(1, values)\n",
        "    print(keys[np.argmax(sample)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "quick\n",
            "only\n",
            "just\n",
            "quick\n",
            "in\n",
            "struck\n",
            "determined\n",
            "all\n",
            ".\n",
            "but\n",
            "pitched\n",
            "mistaken\n",
            "experienced\n",
            ".\n",
            "pitched\n",
            "telling\n",
            "in\n",
            "in\n",
            "all\n",
            ".\n",
            "struck\n",
            "just\n",
            "but\n",
            "experienced\n",
            "experienced\n",
            "now\n",
            "that\n",
            "eating\n",
            "determined\n",
            "experienced\n",
            "in\n",
            "now\n",
            "telling\n",
            "an\n",
            "determined\n",
            "in\n",
            "in\n",
            "dead\n",
            "all\n",
            "dead\n",
            "quick\n",
            "all\n",
            "in\n",
            "just\n",
            "that\n",
            "struck\n",
            ".\n",
            "but\n",
            ",\n",
            "all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9glS5aGFFuiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e683ac6-d43b-4748-9b03-e538e7c495e2"
      },
      "source": [
        "sample_next_word('as', 'a'), counts[('as', 'a')]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('general',\n",
              " defaultdict(<function __main__.<lambda>.<locals>.<lambda>>,\n",
              "             {'Commodore': 1.001,\n",
              "              'Dish': 1.001,\n",
              "              'Latin': 1.001,\n",
              "              'Roman': 1.001,\n",
              "              'backwoodsman': 1.001,\n",
              "              'bat': 1.001,\n",
              "              'birch': 1.001,\n",
              "              'body': 2.001,\n",
              "              'candidate': 1.001,\n",
              "              'cat': 1.001,\n",
              "              'civilized': 1.001,\n",
              "              'clam': 1.001,\n",
              "              'clock': 1.001,\n",
              "              'coffin': 1.001,\n",
              "              'conceited': 1.001,\n",
              "              'cook': 1.001,\n",
              "              'corpse': 1.001,\n",
              "              'country': 1.001,\n",
              "              'cricket': 1.001,\n",
              "              'crucible': 1.001,\n",
              "              'dead': 1.001,\n",
              "              'dinnerless': 1.001,\n",
              "              'dragon': 1.001,\n",
              "              'drawing': 1.001,\n",
              "              'dromedary': 1.001,\n",
              "              'fin': 1.001,\n",
              "              'flavorish': 1.001,\n",
              "              'fly': 1.001,\n",
              "              'foreshadowing': 1.001,\n",
              "              'frigate': 1.001,\n",
              "              'general': 6.0009999999999994,\n",
              "              'geologist': 1.001,\n",
              "              'giraffe': 1.001,\n",
              "              'god': 1.001,\n",
              "              'golden': 1.001,\n",
              "              'green': 1.001,\n",
              "              'harpoon': 1.001,\n",
              "              'harpooneer': 1.001,\n",
              "              'head': 2.001,\n",
              "              'horse': 1.001,\n",
              "              'journeyman': 1.001,\n",
              "              'lion': 1.001,\n",
              "              'looker': 1.001,\n",
              "              'mace': 1.001,\n",
              "              'man': 3.001,\n",
              "              'mass': 1.001,\n",
              "              'material': 1.001,\n",
              "              'means': 1.001,\n",
              "              'merchant': 1.001,\n",
              "              'mildly': 1.001,\n",
              "              'miller': 1.001,\n",
              "              'model': 1.001,\n",
              "              'modern': 1.001,\n",
              "              'monstrous': 1.001,\n",
              "              'mower': 1.001,\n",
              "              'mule': 1.001,\n",
              "              'murderer': 1.001,\n",
              "              'new': 1.001,\n",
              "              'particular': 1.001,\n",
              "              'passenger': 4.0009999999999994,\n",
              "              'pendulum': 1.001,\n",
              "              'permanent': 1.001,\n",
              "              'picked': 1.001,\n",
              "              'pike': 1.001,\n",
              "              'pile': 1.001,\n",
              "              'pilot': 3.001,\n",
              "              'portent': 1.001,\n",
              "              'rather': 2.001,\n",
              "              'real': 1.001,\n",
              "              'regular': 1.001,\n",
              "              'ripple': 1.001,\n",
              "              'sagacious': 1.001,\n",
              "              'sailor': 3.001,\n",
              "              'sea': 1.001,\n",
              "              'sensible': 1.001,\n",
              "              'set': 1.001,\n",
              "              'signal': 1.001,\n",
              "              'simple': 1.001,\n",
              "              'single': 2.001,\n",
              "              'slave': 1.001,\n",
              "              'small': 1.001,\n",
              "              'solid': 1.001,\n",
              "              'solitary': 1.001,\n",
              "              'sort': 3.001,\n",
              "              'species': 1.001,\n",
              "              'spice': 1.001,\n",
              "              'street': 1.001,\n",
              "              'substitute': 1.001,\n",
              "              'surveyor': 1.001,\n",
              "              'swashing': 1.001,\n",
              "              'tender': 1.001,\n",
              "              'thimbleful': 1.001,\n",
              "              'tossed': 1.001,\n",
              "              'traveller': 1.001,\n",
              "              'vessel': 1.001,\n",
              "              'wash': 1.001,\n",
              "              'weaver': 1.001,\n",
              "              'whaleman': 1.001,\n",
              "              'whistling': 1.001,\n",
              "              'white': 1.001,\n",
              "              'whole': 1.001,\n",
              "              'widow': 1.001,\n",
              "              'young': 1.001}))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqc6nlL4Fui8"
      },
      "source": [
        "We can now generate non-sensical sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG-Cwz-uFui9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde98a40-8f33-4453-dbae-71a59554018b"
      },
      "source": [
        "print(generate())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\" Yes , Captain Sleet , entitled \" The ship !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MStsWKWTFujI"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Modify generate to take any number of initial words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhl9iw-H7ast",
        "outputId": "dcc21168-c00f-43bb-9a11-795ea2a2a37a"
      },
      "source": [
        "def generate_any(initial):\n",
        "    initial = initial.split()\n",
        "    result = [START, START] + initial\n",
        "    next_word = sample_next_word(result[-2], result[-1])\n",
        "    result.append(next_word)\n",
        "    while next_word != STOP:\n",
        "        next_word = sample_next_word(result[-2], result[-1])\n",
        "        result.append(next_word)\n",
        "    \n",
        "    return ' '.join(result[2:-1])\n",
        "\n",
        "print(generate_any('The whale was'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The whale was almost intolerable , it thenceforth becomes a sort of a recently concluded repast , turned , and muttered : \" A Whaling Voyage to Spitzbergen in the bows of the basement of his ivory limb having been inflicted ; now for the great White Whale , that gorge is in request among jewellers and watchmakers .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlg_a9va1OdG",
        "outputId": "2c0b0a61-b3cb-4e93-a7af-409744debfd6"
      },
      "source": [
        "print(generate_any('I want'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I want John .'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fypNuGX1SQN",
        "outputId": "255c4529-7b49-4abd-abd6-28e3572add15"
      },
      "source": [
        "print(generate_any('I will do that'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I will do that last office for the blubber .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGRhSYPg1ZE0",
        "outputId": "3fe18e0d-9cd4-4ca8-83af-76bb676d54f0"
      },
      "source": [
        "print(generate_any('I'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I ' ll go lunging presently .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLn1daWs7vo4",
        "outputId": "d97da5fc-f615-484a-bb0f-1690ad737f02"
      },
      "source": [
        "print(generate_any(''))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "But all in all what mood you are that will drive us on .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE1GCdYlFujP"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Extend the code above to arbitray $n$-gram sizes. Use another corpus to try it with $n=4$.\n",
        "\n",
        "It might be helpful to use a `class` for the LM, make the smoothing a parameter, `counts` a class property, and add a function `fit()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f97lkbMaFujQ"
      },
      "source": [
        "# Your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNVRNgWaarTU"
      },
      "source": [
        "import wget\n",
        "url = 'https://raw.githubusercontent.com/dirkhovy/NLPclass/master/data/tweets_en.txt'\n",
        "wget.download(url, 'tweets_en.txt')\n",
        "tweets = [line.strip() for line in open('tweets_en.txt', encoding='utf8')]\n",
        " \n",
        "lm = LM(smoothing=0.001, n_grams_size=4)\n",
        "lm.fit(document=tweets)\n",
        "print(np.unique([lm.generate([\"Trump\",\"should\",\"think\",\"about\"]) \n",
        " for _ in range(10)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI638UW4a_rU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}